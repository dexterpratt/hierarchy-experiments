{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionally Annotate a Hierarchical Model\n",
    "\n",
    "This notebook performs functional analysis on a hierarchical model.\n",
    "\n",
    "Results of this analysis: \n",
    " - communities in the model are annotated with functional enrichment results. \n",
    "  - different enrichment sources are treated separately, nodes annotated with the results on separate properties\n",
    " - a tentative node name is computed\n",
    " - annotations are added to nodes from a tabular data file\n",
    " - a hierarchy style is applied\n",
    "\n",
    "Inputs:\n",
    " - NDEx UUID of the hierarchical model network created by the CyCommunityDetection app\n",
    " - NDEx UUID of an style template network\n",
    "\n",
    "Outputs:\n",
    " - An annotated copy of the hierarchical model network\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ndex2.nice_cx_network import NiceCXNetwork\n",
    "import ndex2.client as nc\n",
    "import ndex2\n",
    "print(\"ndex2 version: \" + ndex2.__version__)\n",
    "import networkx as nx\n",
    "print(\"networkx version: \" + nx.__version__)\n",
    "import pandas as pd\n",
    "print(\"pandas version: \" + pd.__version__)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# functional enrichment service\n",
    "from gprofiler import GProfiler\n",
    "gp = GProfiler(\n",
    "    user_agent='hierarchical model analysis', #optional user agent\n",
    "    return_dataframe=True, #return pandas dataframe or plain python structures    \n",
    "    )\n",
    "\n",
    "# used to prompt user for NDEx password in this notebook\n",
    "import getpass\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the NDEx Account for Output\n",
    "Be sure to hit enter in the field to set the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# used to prompt user for NDEx password in this notebook\n",
    "import getpass\n",
    "my_account = getpass.getpass(prompt='Enter the NDEx account name: ')\n",
    "my_password = getpass.getpass(prompt='Enter the NDEx account password ')\n",
    "my_server = \"http://public.ndexbio.org\" # edit this if you want to use an NDEx server other than the public server\n",
    "# validate the account and password\n",
    "try:\n",
    "    my_ndex=nc.Ndex2(my_server, my_account, my_password)\n",
    "    my_ndex.update_status()\n",
    "    print(\"Success.  Please continue.\")\n",
    "except Exception as inst:\n",
    "    print(\"Could not access account %s with password %s\" % (my_account, my_password))\n",
    "    print(inst.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionally Annotate a Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_sources = []\n",
    "def gprofiler_annotate_community(node_id, model):\n",
    "    members = model.get_node_attribute_value(node_id, \"CD_MemberList\")\n",
    "    profile = gp.profile(organism='hsapiens',\n",
    "                     query = members\n",
    "                     no_evidences=False).head(20)\n",
    "    # for each source, get the top annotation \n",
    "    annotation_map = {}\n",
    "    name = None\n",
    "    for index, row in profile.iterrows():\n",
    "        if row[\"significant\"] is True:\n",
    "            if name is none:\n",
    "                model.set_node_name(node_id, profile[\"name\"]) # the first significant annotation is the node name\n",
    "            source = row[\"source\"]\n",
    "            name = profile[\"name\"]\n",
    "        if annotation_map[source] is None:\n",
    "            annotation_map[source] = name\n",
    "            \n",
    "    for source, annotation in annotation_map:\n",
    "        model.set_node_attribute_value(node_id, model, source, annotation)\n",
    "\n",
    "    \n",
    "def protein_data_annotate_community(node_id, model, pd_df, attribute_column_name):\n",
    "    members = model.get_node_attribute_value(node_id, \"CD_MemberList\")\n",
    "    annotated_genes = pd_df[attribute_column_name]\n",
    "    attribute_member_names = attribute_column_name + \"_genes\"\n",
    "    attribute_member_count = attribute_column_name + \"_count\"\n",
    "    \n",
    "    for member in members:\n",
    "        if member in annotated_genes:\n",
    "            annotated_members.append[member]\n",
    "            annotated_member_count += 1\n",
    "    \n",
    "    model.set_node_attribute_value(node_id, model, attribute_member_names, annotated_members, \"list_of_string\")\n",
    "    model.set_node_attribute_value(node_id, model, attribute_member_count, annotated_members, \"integer\")\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uuid = \"5d97a04a-6fab-11ea-bfdc-0ac135e8bacf\" \n",
    "model = ndex2.create_nice_cx_from_server(server='public.ndexbio.org', \n",
    "                                                          uuid=model_uuid, \n",
    "                                                          password=my_password, \n",
    "                                                          username=my_account)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Annotation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_annotation_file = \"\"\n",
    "protein_annotation_df = pd.read_csv(protein_annotation_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Style Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_template_uuid = \"5d97a04a-6fab-11ea-bfdc-0ac135e8bacf\" \n",
    "stylt_template = ndex2.create_nice_cx_from_server(server='public.ndexbio.org', \n",
    "                                                          uuid=style_template_uuid, \n",
    "                                                          password=my_password, \n",
    "                                                          username=my_account)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the nodes (communities) in the model\n",
    "for node_id, node in model.get_nodes():\n",
    "    gprofiler_annotate_community(node_id,model)\n",
    "    protein_data_annotate_community(node_id, model, protein_annotation_df, attribute_column_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Functional Annotation of All Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the nodes (communities) in the model\n",
    "for node_id, node in model.get_nodes():\n",
    "    annotate_community(node_id,model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Annotated Model to NDEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_message = model.upload_to(my_server, my_account, my_password)\n",
    "upload_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD STUFF AFTER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_network_uuid = \"5d97a04a-6fab-11ea-bfdc-0ac135e8bacf\" \n",
    "interaction_map = ndex2.create_nice_cx_from_server(server='public.ndexbio.org', \n",
    "                                                          uuid=sars_cov2_interactions_uuid, \n",
    "                                                          password=my_password, \n",
    "                                                          username=my_account)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def nice_cx_to_node_dataframe(nice_cx_network):\n",
    "    \"\"\"\n",
    "    Create a Pandas DataFrame in which each row is a node and columns are node attributes.\n",
    "     Example:\n",
    "        ``df = nice_cx_to_node_dataframe(my_nice_cx_network) # df is now a pandas dataframe``\n",
    "    :return: Pandas dataframe\n",
    "    :rtype: Pandas dataframe\n",
    "    \"\"\"\n",
    "    #TODO expand documentation\n",
    "    rows = []\n",
    "    node_items = None\n",
    "    if sys.version_info.major == 3:\n",
    "        node_items = nice_cx_network.nodes.items()\n",
    "    else:\n",
    "        node_items = nice_cx_network.nodes.iteritems()\n",
    "    # v is the node item values\n",
    "    # k is the index of the node\n",
    "    attribute_names = {\"name\", \"node_id\"}\n",
    "    for node_id, v in node_items:\n",
    "        row = {}\n",
    "        row[\"name\"] = v.get('n')\n",
    "        row[\"node_id\"] = node_id\n",
    "        for attribute in nice_cx_network.get_node_attributes(node_id):\n",
    "            attribute_names.add(attribute.get('n'))\n",
    "            row[attribute.get('n')] = attribute.get('v')\n",
    "        rows.append(row)\n",
    "    df_columns = list(attribute_names)\n",
    "    return_df = pd.DataFrame(rows, columns=df_columns)\n",
    "    return return_df\n",
    "\n",
    "def jaccard_similarity_lists(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "def jaccard_similarity_sets(set1, set2):\n",
    "    intersection = len(list(set1.intersection(set2)))\n",
    "    union = (len(set1) + len(set2)) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Query Shortcuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Output Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Functions\n",
    "\n",
    "Output Table:\n",
    "- term name  (name is CD_CommunityName otherwise method:name)\n",
    "- viral proteins\n",
    "- curated: yes, no, similar, more specific, more general\n",
    "- curated interactors\n",
    "- hidef\n",
    "- louvain\n",
    "- infomap\n",
    "- oslom\n",
    " \n",
    "for each method:\n",
    "\n",
    "- members\n",
    "- interactor members\n",
    "- interactor members direct\n",
    "- google members\n",
    "\n",
    "\n",
    "##### Annotate Communities with Interactor Proteins, both direct and all\n",
    "\n",
    "##### Annotate Communities with Viral Proteins\n",
    "\n",
    "#####\n",
    "\n",
    "The goal is to have the viral proteins at the core of the network, connecting to their interactors. Each interactor is in turn connected to the terms in the hierarchy to which it is _directly_ annotated. Unfortunately the direct annotations are not distinguished from the indirect in this data. We therefore need to compute that by finding the terms that contain the interactor AND that have no child node that contains the interactor\n",
    "\n",
    "We populate a dict, int_to_com in which the keys are interactors and the values are sets of communities, initiallized to empty sets.\n",
    "- for each interactor:\n",
    "-- for each community:\n",
    "    if the the interactor is in the community, add the community to the set associated with the interactor.\n",
    "    \n",
    "We now prune each set of communities. For each community C in the list, iterate over the edges in the network. We only want to keep C if it has no parents, i.e. if there is any edge in which C is the target, remove it from the set. \n",
    "\n",
    "When the set is pruned, add an edge from the interactor to each remaining community.\n",
    "\n",
    "\n",
    "Issues:\n",
    "- connecting the interactors to the communities isn't working - connections were all to corum root\n",
    "- need to ditch the big nodes\n",
    "- get rid of terms that don't connect to an interactor\n",
    "- need a column for label\n",
    "- need a column for type\n",
    "- where are the viral protein links\n",
    "- include all the bioplex edges between interactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactor_viral_map = {}\n",
    "\n",
    "for edge_id, edge in sars_cov2_interactions.get_edges():\n",
    "    preys = sars_cov2_interactions.get_edge_attribute_value(edge_id, \"Preys\")\n",
    "    #print(preys)\n",
    "    if isinstance(preys, str):\n",
    "        bait = sars_cov2_interactions.nodes.get(edge[\"s\"]).get(\"n\")\n",
    "        prey = sars_cov2_interactions.nodes.get(edge[\"t\"]).get(\"n\")\n",
    "        interactor_viral_map[prey] = bait\n",
    "    \n",
    "\n",
    "def format_google_search(list_of_strings):\n",
    "    search_string = \"+\".join(list_of_strings)\n",
    "    return '=HYPERLINK(\"https://www.google.com/search?q=\" + search_string, \"google\")'\n",
    "\n",
    "# there is a classy list comprehension way to do this...:-(\n",
    "def get_viral_proteins(interactor_list, interactor_viral_map):\n",
    "    viral = set()\n",
    "    for interactor in interactor_list:\n",
    "        vp = interactor_viral_map.get(interactor)\n",
    "        if vp is not None:\n",
    "            viral.add(vp)\n",
    "    return list(viral)\n",
    "\n",
    "def community_name_analysis(hierarchy_network, community_name_map, cd_method, interactors, interactor_viral_map):\n",
    "    interactor_set = set(interactors)\n",
    "    for node_id, node in hierarchy_network.get_nodes():\n",
    "        # determine the community name\n",
    "        community_name = hierarchy_network.get_node_attribute_value(node_id, \"CD_CommunityName\")\n",
    "        if community_name == \"(none)\":\n",
    "            community_name = node.get('n')\n",
    "        # community_name = hierarchy_network.nodes.get(node_id).get(\"n\")\n",
    "        cdict = community_name_map.get(node.get(\"n\"))\n",
    "        # if there is no entry in the community_name_map, make one\n",
    "        if cdict is None:\n",
    "            cdict = {}\n",
    "            community_name_map[node.get(\"n\")] = cdict\n",
    "           # cdict[\"curated\"] = \"?\"  # later, this will be filled in manually in the resulting spreadsheet\n",
    "            #cdict[\"curated_interactors\"] = \"?\"\n",
    "\n",
    "        cdict[\"name\"] = community_name\n",
    "        members = hierarchy_network.get_node_attribute_value(node_id, \"CD_MemberList\").split(\" \")\n",
    "        interactors = list(set(members).intersection(interactor_set))\n",
    "        if cd_method is None:\n",
    "            cdict[\"members\"] = members\n",
    "            cdict[\"interactors\"] = interactors\n",
    "            cdict[\"#int\"] = len(interactors)\n",
    "            cdict[\"viral\"] = get_viral_proteins(interactors, interactor_viral_map)\n",
    "        else:\n",
    "            cdict[cd_method] = True # shows that this method found a term with this name  \n",
    "            cdict[cd_method + \":members\"] = members\n",
    "            cdict[cd_method + \":interactors\"] = interactors\n",
    "            cdict[cd_method + \":#int\"] = len(interactors)\n",
    "            cdict[cd_method + \":viral\"] = get_viral_proteins(interactors, interactor_viral_map)\n",
    "            # TODO: interactors directly annotated to term\n",
    "            #if len(members)<10:\n",
    "            #    cdict[cd_method + \":google\"] = format_google_search(members)\n",
    "    \n",
    "    return community_name_map\n",
    "              \n",
    "def analyze_cd_methods(community_name_map, methods, interactor_viral_map):\n",
    "    first_columns = [] #[\"curated\", \"curated_interactors\"]\n",
    "    method_name_columns = []\n",
    "    method_member_columns = []\n",
    "    method_interactor_columns = []\n",
    "    for method_name, method_model in methods.items():\n",
    "        community_name_analysis(method_model, community_name_map, method_name, \n",
    "                                sars_cov2_interactors, interactor_viral_map)\n",
    "        method_name_columns.append(method_name)\n",
    "        method_member_columns.append(method_name + \":members\")\n",
    "        method_interactor_columns.append(method_name + \":viral\")\n",
    "        method_interactor_columns.append(method_name + \":interactors\")\n",
    "        method_interactor_columns.append(method_name + \":#int\")\n",
    "    \n",
    "    # post-process\n",
    "    for method_name, method in methods.items():\n",
    "        for community_name, columns in community_name_map.items():\n",
    "            if columns.get(method_name) is None:\n",
    "                columns[method_name] = False\n",
    "                columns[method_name + \":members\"] = []\n",
    "                columns[method_name + \":interactors\"] = []\n",
    "                columns[method_name + \":#int\"] = 0\n",
    "                columns[method_name + \":viral\"] = []\n",
    "                \n",
    "    columns = first_columns + method_name_columns + method_interactor_columns + method_member_columns\n",
    "    return columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process One Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_name_map = {}\n",
    "community_name_map = community_name_analysis(hidef_model, \n",
    "                                             community_name_map, \n",
    "                                             None, \n",
    "                                             sars_cov2_interactors, \n",
    "                                             interactor_viral_map)\n",
    "community_name_df = pd.DataFrame.from_dict(community_name_map, orient=\"index\")\n",
    "community_name_df = community_name_df.sort_values(by=['#int'])\n",
    "only_two = community_name_df.loc[community_name_df['#int'] == 2]\n",
    "only_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Multiple Hierarchies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_methods = {\n",
    "    \"hidef\": hidef_model,\n",
    "    #\"louvain\": louvain_model,\n",
    "    #\"infomap\": infomap_model,\n",
    "    #\"oslom\" : oslom_model\n",
    "    }\n",
    "community_name_map = {}\n",
    "\n",
    "columns = analyze_cd_methods(community_name_map, cd_methods, interactor_viral_map)\n",
    "#community_name_map = community_name_analysis(louvain_model, community_name_map, \"louvain\", sars_cov2_interactors)\n",
    "#community_name_map = community_name_analysis(oslom_model, community_name_map, \"oslom\", sars_cov2_interactors)\n",
    "\n",
    "community_name_df = pd.DataFrame.from_dict(community_name_map, orient=\"index\")\n",
    "community_name_df = community_name_df[columns]\n",
    "community_name_df = community_name_df.sort_values(by=['hidef:#int'])\n",
    "\n",
    "community_name_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret one community\n",
    "Use the g:Profiler client to get the top n terms enriched for the community\n",
    "\n",
    "Create a dataframe in which the the terms are rows sorted by overlap\n",
    "The columns are:\n",
    "\n",
    " - name (term_name)\n",
    " - id (term_id)\n",
    " - anot (count of annotated proteins)\n",
    " - anot_list\n",
    " - pv (enrichment p-value)\n",
    " - vir (viral proteins in anot_list)\n",
    " - int (count of interactors in anot_list)\n",
    " - columns for community\n",
    " -  value is 0, 1, 2 where 2 indicates an interactor gene\n",
    "  - sorted by # occurances across communities, or maybe just sum of the gene column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_community_interpretation(name, community_name_map):\n",
    "    community = community_name_map.get(name)\n",
    "    profile = gp.profile(organism='hsapiens',\n",
    "                         query= community.get(\"members\"),\n",
    "                         no_evidences=False).head(20)\n",
    "    \n",
    "    #i_df = profile\n",
    "    i_df = profile.loc[:, (\"name\", \"native\", \"intersection_size\", \"p_value\")]\n",
    "    i_df.rename(columns={'native': 'id', 'intersection_size': '#anot', \"p_value\": \"pv\"},\n",
    "                             inplace=True)\n",
    "    term_columns = list(i_df.columns.values)\n",
    "    annotation_counts = {}\n",
    "    interactors = community.get(\"interactors\")\n",
    "    for gene_name in community.get(\"members\"):\n",
    "        # add a column to i_df for each gene_name\n",
    "        i_df[gene_name] = 0\n",
    "        annotation_counts[gene_name] = 0\n",
    "           \n",
    "    for index, row in profile.iterrows():\n",
    "        #print(index)\n",
    "        #print(row[\"name\"])\n",
    "        for gene_name in row[\"intersections\"]:\n",
    "            #print(i_df[gene_name][index])\n",
    "            if gene_name in interactors:\n",
    "                i_df.at[index, gene_name] = 2\n",
    "            else:\n",
    "                i_df.at[index, gene_name] = 1\n",
    "            annotation_counts[gene_name] += 1\n",
    "    \n",
    "    gene_columns = [k for k, v in sorted(annotation_counts.items(), key=lambda item: item[1], reverse=True)]\n",
    "    i_df_columns = term_columns + gene_columns\n",
    "    i_df = i_df[i_df_columns]\n",
    "                           \n",
    "    return i_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {\"foo\": 2, \"bar\": 4, \"baz\": 3, \"qux\": 1, \"ick\": 0}\n",
    "[k for k, v in sorted(x.items(), key=lambda item: item[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_name = \"C124261\"\n",
    "inter_df = make_community_interpretation(comm_name, community_name_map)\n",
    "\n",
    "\n",
    "inter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df.to_excel(\"~/Desktop/\" + comm_name + \".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(inter_df.columns),\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=inter_df.transpose().values.tolist(),\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_name_df.to_excel(\"~/Desktop/community_name_4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        in\n",
    "        interactor_name_to_id_map = {}\n",
    "        for interactor_name in sars_cov2_interactors:\n",
    "            interactor_to_commmunity_map[interactor_name] = set()\n",
    "            if isinstance(members, str):\n",
    "                # the node is a community if it has members\n",
    "                #print(members, node)\n",
    "                for member_name in members.split(\" \"):\n",
    "                    #print(member_name)\n",
    "                    community_set = interactor_to_commmunity_map.get(member_name)\n",
    "                    #print(community_set)\n",
    "                    if community_set is not None:\n",
    "                        community_set.add(node_id)\n",
    "else:\n",
    "                # the node is an interactor\n",
    "                interactor_name_to_id[node[\"n\"]] = node[\"@id\"]\n",
    "    \n",
    "interactor_name_to_id\n",
    "interactor_to_commmunity_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"hierarchy edges before: \", len(hierarchy_network.edges))\n",
    "\n",
    "for interactor_name, community_set in int_to_com.items():\n",
    "    communities_to_remove = set()\n",
    "    for edge_id, edge in hierarchy_network.edges.items():\n",
    "        if edge['s'] in community_set and edge['t'] in community_set:\n",
    "            communities_to_remove.add(edge['s'])\n",
    "    print(\"communities to remove: \", len(communities_to_remove))\n",
    "    communities_to_connect = community_set.difference(communities_to_remove)\n",
    "    \n",
    "    for community_id in communities_to_connect:\n",
    "        # add edge from interactor_id to community_id\n",
    "        interactor_id = interactor_name_to_id[interactor_name]\n",
    "        hierarchy_network.create_edge(edge_source=interactor_id, edge_target=community_id, edge_interaction='member_of')\n",
    "        \n",
    "            \n",
    "#print(\"hierarchy edges after: \", len(hierarchy_network.edges))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add New Attributes to Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df.to_excel(hierarchy_network.get_name() + \" nodes.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
